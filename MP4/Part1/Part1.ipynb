{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import pprint\n",
    "import pygame\n",
    "import sys\n",
    "\n",
    "#===========CHANGABLE PARAMETERS=================\n",
    "REWARD     = 1\n",
    "PENALTY    = -1\n",
    "DISCOUNT   = 0.9\n",
    "LEARN_RATE_CONST = 200\n",
    "\n",
    "def get_explore_rate(epoch):\n",
    "    return max(0.1,1-math.log2(epoch*1000)/20)\n",
    "\n",
    "#===========DEFINE CONSTANTS AND DICS=============\n",
    "WALL_LEN = 1\n",
    "PADDLE_H = 0.2\n",
    "\n",
    "init_state = (0.5, 0.5, 0.03, 0.01, 0.5 - PADDLE_H / 2)\n",
    "\n",
    "ACTION_DIC={0:-0.04, #'UP'\n",
    "            1:0,     #'STAY'\n",
    "            2:0.04}  #'DOWN'\n",
    "\n",
    "BOARD_SIZE = 12\n",
    "X_VBALL_DIS = [-1,1]\n",
    "Y_VBALL_DIS = [-1,0,1]\n",
    "\n",
    "PADDLE_SPACE = 12\n",
    "PADDLE_X     = 1\n",
    "\n",
    "STATE_SPACE = (BOARD_SIZE,BOARD_SIZE,len(X_VBALL_DIS),len(Y_VBALL_DIS),PADDLE_SPACE)\n",
    "\n",
    "X_V_TSH = 0.03\n",
    "Y_V_TSH = 0.015\n",
    "\n",
    "#==============DEFINE STATE CLASS===============\n",
    "class state:\n",
    "    \n",
    "    def __init__(self,ball_x,ball_y,velocity_x,velocity_y,paddle_y,reward,end_state = 0):\n",
    "        self.ball_x = ball_x              #real numbers on the interval [0,1]\n",
    "        self.ball_y = ball_y\n",
    "        self.velocity_x = velocity_x\n",
    "        self.velocity_y = velocity_y\n",
    "        self.paddle_y = paddle_y\n",
    "        self.reward = reward\n",
    "        self.state_tuple = (ball_x,ball_y,velocity_x,velocity_y,paddle_y)\n",
    "        self.end_state = end_state\n",
    "        self._extract()\n",
    "        \n",
    "    def _extract(self):\n",
    "        self.x_grid = min(math.floor(12*self.ball_x),BOARD_SIZE-1)\n",
    "        self.y_grid = min(math.floor(12*self.ball_y),BOARD_SIZE-1)\n",
    "        if(self.velocity_x>0): \n",
    "            self.x_v_sign = 0\n",
    "        else: \n",
    "            self.x_v_sign = 1\n",
    "            \n",
    "        if(self.velocity_y>=0.015):\n",
    "            self.y_v_sign = 0\n",
    "        elif(self.velocity_y<=0.015): \n",
    "            self.y_v_sign = 1\n",
    "        else:\n",
    "            self.y_v_sign = 2\n",
    "        self.paddle_grid = min(math.floor(12 * self.paddle_y / (1 - PADDLE_H)),PADDLE_SPACE-1)\n",
    "        self.space_tuple = (self.x_grid,self.y_grid,self.x_v_sign,self.y_v_sign,self.paddle_grid)\n",
    "        \n",
    "#=============DEFINE Q-AGENT CLASS==============\n",
    "class q_agent:\n",
    "    \n",
    "    def __init__(self,mode = 'new'):\n",
    "        if mode == 'new':\n",
    "            print('successfully generate a new Q-Agent!')\n",
    "            self.q_table = np.zeros(STATE_SPACE+(len(ACTION_DIC),)) \n",
    "            self.table_vis = np.zeros(STATE_SPACE+(len(ACTION_DIC),))\n",
    "            self.end_state = 0\n",
    "        elif mode == 'load':\n",
    "            print('loading past data...')\n",
    "            self.q_table = np.load('qtable.npy')\n",
    "            self.table_vis = np.load('tablevis.npy')\n",
    "            print('successfully load data')\n",
    "        else:\n",
    "            print('cannot read the mode, exit')\n",
    "            sys.exit()\n",
    "        \n",
    "    def set_table(self,loc,val):\n",
    "        self.q_table[loc] = val\n",
    "    \n",
    "    def get_table(self,loc):\n",
    "        return self.q_table[loc]\n",
    "\n",
    "    def get_c(self,loc):\n",
    "        return self.table_vis[loc]\n",
    "    \n",
    "    def set_c(self,loc,val):\n",
    "        self.table_vis[loc] = val\n",
    "        \n",
    "    def get_act(self,cur_state,i,mode = 'train',learning='Q'):\n",
    "        if mode=='train' and random.random()<get_explore_rate(i):\n",
    "            return random.choice(range(0,3,1))\n",
    "        return np.argmax(self.get_table(cur_state.space_tuple))\n",
    "    \n",
    "\n",
    "#=======DEFINE MORE HELPER FUNCTIONS===========\n",
    "def bounce(cur_state,action,mode = 'Part1.1'):\n",
    "    n_ball_v_x = cur_state.velocity_x\n",
    "    n_ball_v_y = cur_state.velocity_y\n",
    "\n",
    "    n_ball_x = cur_state.ball_x + n_ball_v_x\n",
    "    n_ball_y = cur_state.ball_y + n_ball_v_y\n",
    "\n",
    "    fac = n_ball_v_y*(1-cur_state.ball_x)/n_ball_v_x #for 1.1\n",
    "    cmp_y = cur_state.ball_y + fac\n",
    "    \n",
    "    fac_2 = n_ball_v_y*(cur_state.ball_x)/n_ball_v_x\n",
    "    cmp_y_2 = cur_state.ball_y + fac_2\n",
    "    #======paddle should in range(0,0.8)=====\n",
    "    n_paddle_y = min(WALL_LEN-PADDLE_H,max(0,cur_state.paddle_y + action))\n",
    "    \n",
    "    c_reward = 0\n",
    "    \n",
    "    #==the ball is off the top of the screen==\n",
    "    if n_ball_y < 0:\n",
    "        n_ball_y = -n_ball_y\n",
    "        n_ball_v_y = -n_ball_v_y\n",
    "        \n",
    "    #==the ball is off the bottom of the screen==\n",
    "    if n_ball_y > 1:\n",
    "        n_ball_y = 2*WALL_LEN-n_ball_y\n",
    "        n_ball_v_y = -n_ball_v_y\n",
    "    \n",
    "    #==the ball is off the left edge of the screen== ###PART1.1\n",
    "    if n_ball_x < 0 and mode == 'Part1.1':\n",
    "        n_ball_x = -n_ball_x\n",
    "        n_ball_v_x = -n_ball_v_x\n",
    "    #== the ball bouncing off the paddle==\n",
    "    if n_ball_x >= 1 and mode == 'Part1.1' and (n_paddle_y+PADDLE_H >= min(max(0,cmp_y),1) >= n_paddle_y):\n",
    "        n_ball_x = 2*PADDLE_X - n_ball_x\n",
    "        n_ball_v_x, n_ball_v_y = update_speed_rand(n_ball_v_x,n_ball_v_y)\n",
    "        c_reward = REWARD\n",
    "    elif n_ball_x > 1 and mode == 'Part1.1':\n",
    "        c_reward = PENALTY\n",
    "    \n",
    "    #==the ball is off the left edge of the screen== ###PART1.2\n",
    "    if n_ball_x > 1 and mode == 'Part1.2':\n",
    "        n_ball_x = 2*WALL_LEN - n_ball_x\n",
    "        n_ball_v_x = -n_ball_v_x\n",
    "    #== the ball bouncing off the paddle==\n",
    "    if n_ball_x <= 0 and mode == 'Part1.2' and (n_paddle_y+PADDLE_H >= min(max(0,cmp_y_2),1) >= n_paddle_y):\n",
    "        n_ball_x = - n_ball_x\n",
    "        n_ball_v_x, n_ball_v_y = update_speed_rand(n_ball_v_x,n_ball_v_y)\n",
    "        c_reward = REWARD\n",
    "    elif n_ball_x < 0 and mode == 'Part1.2':\n",
    "        c_reward = PENALTY\n",
    "   \n",
    "\n",
    "    return n_ball_x,n_ball_y,n_ball_v_x,n_ball_v_y,n_paddle_y,c_reward\n",
    "\n",
    "def update_speed_rand(velocity_x,velocity_y):\n",
    "    vx_delta = random.choice(range(-1,2,2)) * random.choice(range(0,16,1)) / 1000\n",
    "    vy_delta = random.choice(range(-1,2,2)) * random.choice(range(0,4,1))  / 100\n",
    "    sign_x = -velocity_x/abs(velocity_x)\n",
    "    sign_y = velocity_y/abs(velocity_y)\n",
    "    n_ball_v_x = sign_x*max(X_V_TSH,min(1,abs(vx_delta+velocity_x)))\n",
    "    n_ball_v_y = sign_y*max(Y_V_TSH,min(1,abs(vy_delta+velocity_y)))\n",
    "    return n_ball_v_x, n_ball_v_y\n",
    "\n",
    "def proceed_one_step(cur_state,action,mode = 'Part1.1'):\n",
    "\n",
    "    n_ball_x,n_ball_y,n_ball_v_x,n_ball_v_y,n_paddle_y,c_reward = bounce(cur_state,action,mode)\n",
    "    end = 0\n",
    "    if c_reward == -1:\n",
    "        end = 1\n",
    "    n_state = state(n_ball_x,n_ball_y,n_ball_v_x,n_ball_v_y,n_paddle_y,c_reward,end_state=end)\n",
    "    return n_state\n",
    "\n",
    "#=============DEFINE TRAIN FUCNTION=============\n",
    "def train(epoch_num,q_ag,mode = 'Part1.1',learning = 'Q'):\n",
    "    pre_tot = 0\n",
    "    tot_bounce = 0\n",
    "    for i in range(1,epoch_num+1):\n",
    "        temp_bounce = 0\n",
    "        \n",
    "        if mode == 'Part1.1':\n",
    "            cur_state = state(0.5, 0.5, 0.03, 0.01, 0.5 - PADDLE_H / 2,0)\n",
    "            sarsa_act = 0\n",
    "        elif mode == 'Part1.2':\n",
    "            cur_state = state(0.5, 0.5, -0.03, 0.01, 0.5 - PADDLE_H / 2,0)\n",
    "            sarsa_act = 0\n",
    "        while True:\n",
    "\n",
    "            if learning == 'Q':\n",
    "                \n",
    "                action = q_ag.get_act(cur_state,i,learning)\n",
    "                n_state = proceed_one_step(cur_state,ACTION_DIC[action],mode)\n",
    "            \n",
    "                old_val = q_ag.get_table(cur_state.space_tuple+(action,))\n",
    "                prd_max = np.max(q_ag.get_table(n_state.space_tuple))\n",
    "#                 prd_tuple = (n_state.x_grid,n_state.y_grid,n_state.x_v_sign,n_state.y_v_sign,n_state.paddle_grid,prd_max)\n",
    "\n",
    "                Nsa = q_ag.get_c(cur_state.space_tuple+(action,))\n",
    "                learn_rate = LEARN_RATE_CONST/(LEARN_RATE_CONST+Nsa)\n",
    "                q_ag.set_c(cur_state.space_tuple+(action,),Nsa+1)\n",
    "\n",
    "                new_val = (1-learn_rate)*old_val + learn_rate*(n_state.reward + DISCOUNT*prd_max)\n",
    "                q_ag.set_table(cur_state.space_tuple+(action,),new_val)\n",
    "                \n",
    "                \n",
    "                \n",
    "            elif learning == 'SARSA':\n",
    "                \n",
    "                n_state = proceed_one_step(cur_state,ACTION_DIC[sarsa_act],mode)\n",
    "                \n",
    "                n_sarsa_act = q_ag.get_act(n_state,i,learning)\n",
    "                \n",
    "                \n",
    "                old_val = q_ag.get_table(cur_state.space_tuple+(sarsa_act,))\n",
    "                prd_max = q_ag.get_table(n_state.space_tuple+(n_sarsa_act,))\n",
    "#                 prd_tuple = (n_state.x_grid,n_state.y_grid,n_state.x_v_sign,n_state.y_v_sign,n_state.paddle_grid,prd_max)\n",
    "\n",
    "                Nsa = q_ag.get_c(cur_state.space_tuple+(sarsa_act,))\n",
    "                learn_rate = LEARN_RATE_CONST/(LEARN_RATE_CONST+Nsa)\n",
    "                q_ag.set_c(cur_state.space_tuple+(sarsa_act,),Nsa+1)\n",
    "\n",
    "                new_val = (1-learn_rate)*old_val + learn_rate*(n_state.reward + DISCOUNT*prd_max)\n",
    "                q_ag.set_table(cur_state.space_tuple+(sarsa_act,),new_val)\n",
    "                \n",
    "                sarsa_act = n_sarsa_act\n",
    "            \n",
    "            else: \n",
    "                print('Wrong learning input!')\n",
    "                sys.exit()    \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "            if n_state.end_state == 1:\n",
    "                break\n",
    "            if n_state.reward == REWARD:\n",
    "                temp_bounce+=1\n",
    "            cur_state = n_state\n",
    "        tot_bounce+=temp_bounce\n",
    "        if i%1000 == 0:\n",
    "            print('loop',i)\n",
    "            print('now average bounce in this 1000 round is', (tot_bounce-pre_tot)/1000)\n",
    "            print('bounce=',tot_bounce-pre_tot)\n",
    "            print()\n",
    "            pre_tot = tot_bounce\n",
    "            \n",
    "#================DEFINE TEST FUNCTION============\n",
    "def test(epoch_num,q_ag,mode = 'Part1.1'):\n",
    "    print('testing')\n",
    "    tot_bounce = 0\n",
    "    for i in range(epoch_num):\n",
    "        temp_bounce = 0\n",
    "        \n",
    "        if mode == 'Part1.1':\n",
    "            cur_state = state(0.5, 0.5, 0.03, 0.01, 0.5 - PADDLE_H / 2,0)\n",
    "        elif mode == 'Part1.2':\n",
    "            cur_state = state(0.5, 0.5, -0.03, 0.01, 0.5 - PADDLE_H / 2,0)\n",
    "            \n",
    "        while True:\n",
    "            action = q_ag.get_act(cur_state,i,mode='hei')\n",
    "            n_state = proceed_one_step(cur_state,ACTION_DIC[action],mode)\n",
    "            if n_state.end_state == 1:\n",
    "                break\n",
    "            if n_state.reward == REWARD:\n",
    "                temp_bounce+=1\n",
    "            cur_state = n_state\n",
    "        tot_bounce+=temp_bounce\n",
    "    \n",
    "    print('the avg bounce =',tot_bounce/epoch_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#=========================VISUALIZATION VERSION========================\n",
    "WHITE = (255, 255, 255)\n",
    "BLACK = (0,0,0)\n",
    "BALL_COLOR = (255,186,186)\n",
    "PAD_COLOR = (182, 209, 204)\n",
    "BACKGROUND_COLOR = (255, 245, 222)\n",
    "SCORE_COLOR = (25, 118, 210)\n",
    "\n",
    "WIDTH = 600\n",
    "HEIGHT = 600\n",
    "\n",
    "BALL_RADIUS = 8\n",
    "PAD_WIDTH = 8\n",
    "PAD_HEIGHT = HEIGHT * 0.2\n",
    "HALF_PAD_WIDTH = PAD_WIDTH // 2\n",
    "HALF_PAD_HEIGHT = PAD_HEIGHT // 2\n",
    "GAME_FPS = 30\n",
    "GAME_END_FPS = 30\n",
    "\n",
    "def draw(canvas, ball_x, ball_y, paddle_y, mode = 'Part1.1', player_x = 0, player_y = 0, player_pad = 0):\n",
    "    canvas.fill(BACKGROUND_COLOR)\n",
    "#     pygame.draw.line(canvas, WHITE, [WIDTH // 2, 0], [WIDTH // 2, HEIGHT], 1)\n",
    "#     pygame.draw.line(canvas, WHITE, [PAD_WIDTH, 0], [PAD_WIDTH, HEIGHT], 1)\n",
    "#     pygame.draw.line(canvas, WHITE, [WIDTH - PAD_WIDTH, 0], [WIDTH - PAD_WIDTH, HEIGHT], 1)\n",
    "\n",
    "    if mode == 'Part1.1':\n",
    "        paddle1_pos = (WIDTH + 1 - HALF_PAD_WIDTH, int(paddle_y * HEIGHT + HALF_PAD_HEIGHT))\n",
    "        ball_pos = (int(ball_x * WIDTH) , int(ball_y * HEIGHT))\n",
    "\n",
    "        pygame.draw.circle(canvas, BALL_COLOR, ball_pos, BALL_RADIUS, 0)\n",
    "        pygame.draw.polygon(canvas, PAD_COLOR, [[paddle1_pos[0] - HALF_PAD_WIDTH, paddle1_pos[1] - HALF_PAD_HEIGHT],\n",
    "                                            [paddle1_pos[0] - HALF_PAD_WIDTH, paddle1_pos[1] + HALF_PAD_HEIGHT],\n",
    "                                            [paddle1_pos[0] + HALF_PAD_WIDTH, paddle1_pos[1] + HALF_PAD_HEIGHT],\n",
    "                                            [paddle1_pos[0] + HALF_PAD_WIDTH, paddle1_pos[1] - HALF_PAD_HEIGHT]], 0)\n",
    "\n",
    "    if mode == 'Part1.2':\n",
    "        paddle1_pos = (0 - 1 + HALF_PAD_WIDTH, int(paddle_y * HEIGHT + HALF_PAD_HEIGHT))\n",
    "        ball_pos = (int(ball_x * WIDTH) , int(ball_y * HEIGHT))\n",
    "\n",
    "        pygame.draw.circle(canvas, BALL_COLOR, ball_pos, BALL_RADIUS, 0)\n",
    "        pygame.draw.polygon(canvas, PAD_COLOR, [[paddle1_pos[0] - HALF_PAD_WIDTH, paddle1_pos[1] - HALF_PAD_HEIGHT],\n",
    "                                            [paddle1_pos[0] - HALF_PAD_WIDTH, paddle1_pos[1] + HALF_PAD_HEIGHT],\n",
    "                                            [paddle1_pos[0] + HALF_PAD_WIDTH, paddle1_pos[1] + HALF_PAD_HEIGHT],\n",
    "                                            [paddle1_pos[0] + HALF_PAD_WIDTH, paddle1_pos[1] - HALF_PAD_HEIGHT]], 0)\n",
    "\n",
    "\n",
    "def play(agent, epoches, mode = 'Part1.1'):\n",
    "    \n",
    "    pygame.init()\n",
    "    fps = pygame.time.Clock()\n",
    "\n",
    "    window = pygame.display.set_mode((WIDTH, HEIGHT))\n",
    "    pygame.display.set_caption('Pong')\n",
    "\n",
    "\n",
    "    \n",
    "    rscore = 0\n",
    "\n",
    "    for i in range(epoches):\n",
    "        bounce = 0\n",
    "        temp_bounce = 0\n",
    "        if mode == 'Part1.1':\n",
    "            cur_state = state(0.5, 0.5, 0.03, 0.01, 0.5 - PADDLE_H / 2,0)\n",
    "        elif mode == 'Part1.2':\n",
    "            cur_state = state(0.5, 0.5, -0.03, 0.01, 0.5 - PADDLE_H / 2,0)\n",
    "        while True: \n",
    "            \n",
    "            action = q_ag.get_act(cur_state,i,mode='hei')\n",
    "            for event in pygame.event.get():\n",
    "                if event.type == pygame.QUIT:\n",
    "                    pygame.quit()\n",
    "                    sys.exit()\n",
    "            \n",
    "            \n",
    "            n_state = proceed_one_step(cur_state,ACTION_DIC[action],mode)\n",
    "            \n",
    "            \n",
    "            if n_state.end_state == 1:\n",
    "                break\n",
    "            \n",
    "            draw(window, n_state.ball_x, n_state.ball_y, n_state.paddle_y,mode)\n",
    "            \n",
    "            pygame.display.update()\n",
    "            fps.tick(GAME_FPS)\n",
    "            cur_state = n_state\n",
    "            bounce+=n_state.reward\n",
    "        fps.tick(GAME_END_FPS)\n",
    "        print(bounce)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#======I'VE ALREAD TRAINED THE Q-AGENT SO JUST LOAD==========\n",
    "q_ag = q_agent('load')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully generate a new Q-Agent!\n",
      "loop 1000\n",
      "now average bounce in this 1000 round is 1.656\n",
      "bounce= 1656\n",
      "\n",
      "loop 2000\n",
      "now average bounce in this 1000 round is 2.629\n",
      "bounce= 2629\n",
      "\n",
      "loop 3000\n",
      "now average bounce in this 1000 round is 3.098\n",
      "bounce= 3098\n",
      "\n",
      "loop 4000\n",
      "now average bounce in this 1000 round is 3.655\n",
      "bounce= 3655\n",
      "\n",
      "loop 5000\n",
      "now average bounce in this 1000 round is 4.539\n",
      "bounce= 4539\n",
      "\n",
      "loop 6000\n",
      "now average bounce in this 1000 round is 4.778\n",
      "bounce= 4778\n",
      "\n",
      "loop 7000\n",
      "now average bounce in this 1000 round is 5.515\n",
      "bounce= 5515\n",
      "\n",
      "loop 8000\n",
      "now average bounce in this 1000 round is 5.618\n",
      "bounce= 5618\n",
      "\n",
      "loop 9000\n",
      "now average bounce in this 1000 round is 5.875\n",
      "bounce= 5875\n",
      "\n",
      "loop 10000\n",
      "now average bounce in this 1000 round is 5.59\n",
      "bounce= 5590\n",
      "\n",
      "loop 11000\n",
      "now average bounce in this 1000 round is 5.592\n",
      "bounce= 5592\n",
      "\n",
      "loop 12000\n",
      "now average bounce in this 1000 round is 5.976\n",
      "bounce= 5976\n",
      "\n",
      "loop 13000\n",
      "now average bounce in this 1000 round is 5.817\n",
      "bounce= 5817\n",
      "\n",
      "loop 14000\n",
      "now average bounce in this 1000 round is 5.961\n",
      "bounce= 5961\n",
      "\n",
      "loop 15000\n",
      "now average bounce in this 1000 round is 5.951\n",
      "bounce= 5951\n",
      "\n",
      "loop 16000\n",
      "now average bounce in this 1000 round is 5.864\n",
      "bounce= 5864\n",
      "\n",
      "loop 17000\n",
      "now average bounce in this 1000 round is 5.735\n",
      "bounce= 5735\n",
      "\n",
      "loop 18000\n",
      "now average bounce in this 1000 round is 5.925\n",
      "bounce= 5925\n",
      "\n",
      "loop 19000\n",
      "now average bounce in this 1000 round is 6.018\n",
      "bounce= 6018\n",
      "\n",
      "loop 20000\n",
      "now average bounce in this 1000 round is 5.887\n",
      "bounce= 5887\n",
      "\n",
      "loop 21000\n",
      "now average bounce in this 1000 round is 6.076\n",
      "bounce= 6076\n",
      "\n",
      "loop 22000\n",
      "now average bounce in this 1000 round is 5.8\n",
      "bounce= 5800\n",
      "\n",
      "loop 23000\n",
      "now average bounce in this 1000 round is 6.16\n",
      "bounce= 6160\n",
      "\n",
      "loop 24000\n",
      "now average bounce in this 1000 round is 6.022\n",
      "bounce= 6022\n",
      "\n",
      "loop 25000\n",
      "now average bounce in this 1000 round is 6.0\n",
      "bounce= 6000\n",
      "\n",
      "loop 26000\n",
      "now average bounce in this 1000 round is 5.892\n",
      "bounce= 5892\n",
      "\n",
      "loop 27000\n",
      "now average bounce in this 1000 round is 6.072\n",
      "bounce= 6072\n",
      "\n",
      "loop 28000\n",
      "now average bounce in this 1000 round is 5.849\n",
      "bounce= 5849\n",
      "\n",
      "loop 29000\n",
      "now average bounce in this 1000 round is 5.901\n",
      "bounce= 5901\n",
      "\n",
      "loop 30000\n",
      "now average bounce in this 1000 round is 5.9\n",
      "bounce= 5900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#======ELSE WE CAN DO THIS TO TRAIN==========================\n",
    "# q_ag = q_agent()\n",
    "# train(30000,q_ag,'Part1.2')\n",
    "# np.save('1_2qtable', q_ag.q_table)\n",
    "# np.save('1_2tablevis', q_ag.table_vis)\n",
    "q_sar = q_agent()\n",
    "train(30000,q_sar,'Part1.1','SARSA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing\n",
      "the avg bounce = 13.15\n"
     ]
    }
   ],
   "source": [
    "#======TEST WITHOUT VISUALIZATION============================\n",
    "test(200,q_ag,'Part1.2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "10\n",
      "18\n",
      "4\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "#========PLAY THE GAME!=======================================\n",
    "play(q_ag,5,'Part1.2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
