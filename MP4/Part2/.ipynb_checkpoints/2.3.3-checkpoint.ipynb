{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### import numpy as np\n",
    "import math\n",
    "import random\n",
    "import pprint\n",
    "import syshttp://localhost:8891/notebooks/Desktop/MP4/Part1/Part1.ipynb#\n",
    "import matplotlib.pyplot as plt\n",
    "#===========CHANGABLE PARAMETERS=================\n",
    "REWARD     = 1\n",
    "PENALTY    = -1\n",
    "DISCOUNT   = 0.8\n",
    "LEARN_RATE_CONST = 200\n",
    "\n",
    "def get_explore_rate(epoch):\n",
    "    return max(0.1,1-math.log2(epoch*10)/20)\n",
    "\n",
    "#===========DEFINE CONSTANTS AND DICS=============\n",
    "WALL_LEN = 1\n",
    "PADDLE_H = 0.2\n",
    "\n",
    "init_state = (0.5, 0.5, 0.03, 0.01, 0.5 - PADDLE_H / 2)\n",
    "\n",
    "ACTION_DIC={0:-0.04, #'UP'\n",
    "            1:0,     #'STAY'\n",
    "            2:0.04}  #'DOWN'\n",
    "\n",
    "BOARD_SIZE = 12\n",
    "X_VBALL_DIS = [-1,1]\n",
    "Y_VBALL_DIS = [-1,0,1]\n",
    "\n",
    "PADDLE_SPACE = 12\n",
    "PADDLE_X     = 1\n",
    "\n",
    "STATE_SPACE = (BOARD_SIZE,BOARD_SIZE,len(X_VBALL_DIS),len(Y_VBALL_DIS),PADDLE_SPACE)\n",
    "\n",
    "X_V_TSH = 0.03\n",
    "Y_V_TSH = 0.015\n",
    "\n",
    "#==============DEFINE STATE CLASS===============\n",
    "class state:\n",
    "    \n",
    "    def __init__(self,ball_x,ball_y,velocity_x,velocity_y,paddle_y,reward,end_state = 0):\n",
    "        self.ball_x = ball_x              #real numbers on the interval [0,1]\n",
    "        self.ball_y = ball_y\n",
    "        self.velocity_x = velocity_x\n",
    "        self.velocity_y = velocity_y\n",
    "        self.paddle_y = paddle_y\n",
    "        self.reward = reward\n",
    "        self.state_tuple = (ball_x,ball_y,velocity_x,velocity_y,paddle_y)\n",
    "        self.end_state = end_state\n",
    "        self._extract()\n",
    "        \n",
    "    def _extract(self):\n",
    "        self.x_grid = min(math.floor(12*self.ball_x),BOARD_SIZE-1)\n",
    "        self.y_grid = min(math.floor(12*self.ball_y),BOARD_SIZE-1)\n",
    "        if(self.velocity_x>0): \n",
    "            self.x_v_sign = 0\n",
    "        else: \n",
    "            self.x_v_sign = 1\n",
    "            \n",
    "        if(self.velocity_y>=0.015):\n",
    "            self.y_v_sign = 0\n",
    "        elif(self.velocity_y<=0.015): \n",
    "            self.y_v_sign = 1\n",
    "        else:\n",
    "            self.y_v_sign = 2\n",
    "        self.paddle_grid = min(math.floor(12 * self.paddle_y / (1 - PADDLE_H)),PADDLE_SPACE-1)\n",
    "        self.space_tuple = (self.x_grid,self.y_grid,self.x_v_sign,self.y_v_sign,self.paddle_grid)\n",
    "        \n",
    "#=============DEFINE Q-AGENT CLASS==============\n",
    "class q_agent:\n",
    "    \n",
    "    def __init__(self,mode = 'new',learning = 'Q'):\n",
    "        if mode == 'new':\n",
    "            print('successfully generate a new Q-Agent!')\n",
    "            self.q_table = np.zeros(STATE_SPACE+(len(ACTION_DIC),)) \n",
    "            self.table_vis = np.zeros(STATE_SPACE+(len(ACTION_DIC),))\n",
    "            self.end_state = 0\n",
    "        elif mode == 'load':\n",
    "            print('loading past data...')\n",
    "            if learning == 'Q':\n",
    "                self.q_table = np.load('qtable.npy')\n",
    "                self.table_vis = np.load('tablevis.npy')\n",
    "            elif learning == 'SARSA':\n",
    "                self.q_table = np.load('qtable_sa.npy')\n",
    "                self.table_vis = np.load('tablevis_sa.npy')\n",
    "            else:\n",
    "                print('wrong learning method!')\n",
    "                sys.exit()\n",
    "            print('successfully load data')\n",
    "        else:\n",
    "            print('cannot read the mode, exit')\n",
    "            sys.exit()\n",
    "        \n",
    "    def set_table(self,loc,val):\n",
    "        self.q_table[loc] = val\n",
    "    \n",
    "    def get_table(self,loc):\n",
    "        return self.q_table[loc]\n",
    "\n",
    "    def get_c(self,loc):\n",
    "        return self.table_vis[loc]\n",
    "    \n",
    "    def set_c(self,loc,val):\n",
    "        self.table_vis[loc] = val\n",
    "        \n",
    "    def get_act(self,cur_state,i,mode = 'train',learning='Q'):\n",
    "        if mode=='train' and random.random()<get_explore_rate(i):\n",
    "            return random.choice(range(0,3,1))\n",
    "        return np.argmax(self.get_table(cur_state.space_tuple))\n",
    "    \n",
    "\n",
    "#=======DEFINE MORE HELPER FUNCTIONS===========\n",
    "def bounce(cur_state,action,mode = 'Part1.1'):\n",
    "    n_ball_v_x = cur_state.velocity_x\n",
    "    n_ball_v_y = cur_state.velocity_y\n",
    "\n",
    "    n_ball_x = cur_state.ball_x + n_ball_v_x\n",
    "    n_ball_y = cur_state.ball_y + n_ball_v_y\n",
    "\n",
    "    fac = n_ball_v_y*(1-cur_state.ball_x)/n_ball_v_x #for 1.1\n",
    "    cmp_y = cur_state.ball_y + fac\n",
    "    \n",
    "    fac_2 = n_ball_v_y*(cur_state.ball_x)/n_ball_v_x\n",
    "    cmp_y_2 = cur_state.ball_y + fac_2\n",
    "    #======paddle should in range(0,0.8)=====\n",
    "    n_paddle_y = min(WALL_LEN-PADDLE_H,max(0,cur_state.paddle_y + action))\n",
    "    \n",
    "    c_reward = 0\n",
    "    \n",
    "    #==the ball is off the top of the screen==\n",
    "    if n_ball_y < 0:\n",
    "        n_ball_y = -n_ball_y\n",
    "        n_ball_v_y = -n_ball_v_y\n",
    "        \n",
    "    #==the ball is off the bottom of the screen==\n",
    "    if n_ball_y > 1:\n",
    "        n_ball_y = 2*WALL_LEN-n_ball_y\n",
    "        n_ball_v_y = -n_ball_v_y\n",
    "    \n",
    "    #==the ball is off the left edge of the screen== ###PART1.1\n",
    "    if n_ball_x < 0 and mode == 'Part1.1':\n",
    "        n_ball_x = -n_ball_x\n",
    "        n_ball_v_x = -n_ball_v_x\n",
    "    #== the ball bouncing off the paddle==\n",
    "    if n_ball_x >= 1 and mode == 'Part1.1' and (n_paddle_y+PADDLE_H >= min(max(0,cmp_y),1) >= n_paddle_y):\n",
    "        n_ball_x = 2*PADDLE_X - n_ball_x\n",
    "        n_ball_v_x, n_ball_v_y = update_speed_rand(n_ball_v_x,n_ball_v_y)\n",
    "        c_reward = REWARD\n",
    "    elif n_ball_x > 1 and mode == 'Part1.1':\n",
    "        c_reward = PENALTY\n",
    "    \n",
    "    #==the ball is off the left edge of the screen== ###PART1.2\n",
    "    if n_ball_x > 1 and mode == 'Part1.2':\n",
    "        n_ball_x = 2*WALL_LEN - n_ball_x\n",
    "        n_ball_v_x = -n_ball_v_x\n",
    "    #== the ball bouncing off the paddle==\n",
    "    if n_ball_x <= 0 and mode == 'Part1.2' and (n_paddle_y+PADDLE_H >= min(max(0,cmp_y_2),1) >= n_paddle_y):\n",
    "        n_ball_x = - n_ball_x\n",
    "        n_ball_v_x, n_ball_v_y = update_speed_rand(n_ball_v_x,n_ball_v_y)\n",
    "        c_reward = REWARD\n",
    "    elif n_ball_x < 0 and mode == 'Part1.2':\n",
    "        c_reward = PENALTY\n",
    "   \n",
    "\n",
    "    return n_ball_x,n_ball_y,n_ball_v_x,n_ball_v_y,n_paddle_y,c_reward\n",
    "\n",
    "def update_speed_rand(velocity_x,velocity_y):\n",
    "    vx_delta = random.choice(range(-1,2,2)) * random.choice(range(0,16,1)) / 1000\n",
    "    vy_delta = random.choice(range(-1,2,2)) * random.choice(range(0,4,1))  / 100\n",
    "    sign_x = -velocity_x/abs(velocity_x)\n",
    "    sign_y = velocity_y/abs(velocity_y)\n",
    "    n_ball_v_x = sign_x*max(X_V_TSH,min(1,abs(vx_delta+velocity_x)))\n",
    "    n_ball_v_y = sign_y*max(Y_V_TSH,min(1,abs(vy_delta+velocity_y)))\n",
    "    return n_ball_v_x, n_ball_v_y\n",
    "\n",
    "def proceed_one_step(cur_state,action,mode = 'Part1.1'):\n",
    "\n",
    "    n_ball_x,n_ball_y,n_ball_v_x,n_ball_v_y,n_paddle_y,c_reward = bounce(cur_state,action,mode)\n",
    "    end = 0\n",
    "    if c_reward == -1:\n",
    "        end = 1\n",
    "    n_state = state(n_ball_x,n_ball_y,n_ball_v_x,n_ball_v_y,n_paddle_y,c_reward,end_state=end)\n",
    "    return n_state\n",
    "\n",
    "#=============DEFINE TRAIN FUCNTION=============\n",
    "def train(epoch_num,q_ag,mode = 'Part1.1',learning = 'Q'):\n",
    "    graph = [0]\n",
    "    pre_tot = 0\n",
    "    tot_bounce = 0\n",
    "    for i in range(1,epoch_num+1):\n",
    "        temp_bounce = 0\n",
    "        \n",
    "        if mode == 'Part1.1':\n",
    "            cur_state = state(0.5, 0.5, 0.03, 0.01, 0.5 - PADDLE_H / 2,0)\n",
    "        elif mode == 'Part1.2':\n",
    "            cur_state = state(0.5, 0.5, -0.03, 0.01, 0.5 - PADDLE_H / 2,0)\n",
    "        sarsa_act = q_ag.get_act(cur_state,i)\n",
    "        while True:\n",
    "\n",
    "            if learning == 'Q':\n",
    "                \n",
    "                action = q_ag.get_act(cur_state,i)\n",
    "                n_state = proceed_one_step(cur_state,ACTION_DIC[action],mode)\n",
    "                old_val = q_ag.get_table(cur_state.space_tuple+(action,))\n",
    "\n",
    "\n",
    "                prd_max = np.max(q_ag.get_table(n_state.space_tuple))\n",
    "                prd_tuple = (n_state.x_grid,n_state.y_grid,n_state.x_v_sign,n_state.y_v_sign,n_state.paddle_grid,prd_max)\n",
    "\n",
    "                Nsa = q_ag.get_c(cur_state.space_tuple+(action,))\n",
    "                learn_rate = LEARN_RATE_CONST/(LEARN_RATE_CONST+Nsa)\n",
    "                q_ag.set_c(cur_state.space_tuple+(action,),Nsa+1)\n",
    "\n",
    "                new_val = (1-learn_rate)*old_val + learn_rate*(n_state.reward + DISCOUNT*prd_max)\n",
    "                q_ag.set_table(cur_state.space_tuple+(action,),new_val)\n",
    "\n",
    "                \n",
    "                \n",
    "            elif learning == 'SARSA':\n",
    "                \n",
    "                n_state = proceed_one_step(cur_state,ACTION_DIC[sarsa_act],mode)\n",
    "                \n",
    "                n_sarsa_act = q_ag.get_act(n_state,i)\n",
    "                \n",
    "                old_val = q_ag.get_table(cur_state.space_tuple+(sarsa_act,))\n",
    "\n",
    "\n",
    "                prd_max = q_ag.get_table(n_state.space_tuple+(n_sarsa_act,))\n",
    "#                 prd_tuple = (n_state.x_grid,n_state.y_grid,n_state.x_v_sign,n_state.y_v_sign,n_state.paddle_grid,prd_max)\n",
    "\n",
    "                Nsa = q_ag.get_c(cur_state.space_tuple+(sarsa_act,))\n",
    "                learn_rate = LEARN_RATE_CONST/(LEARN_RATE_CONST+Nsa)\n",
    "                q_ag.set_c(cur_state.space_tuple+(sarsa_act,),Nsa+1)\n",
    "\n",
    "                new_val = (1-learn_rate)*old_val + learn_rate*(n_state.reward + DISCOUNT*prd_max)\n",
    "                q_ag.set_table(cur_state.space_tuple+(sarsa_act,),new_val)\n",
    "                sarsa_act = n_sarsa_act\n",
    "                \n",
    "            else: \n",
    "                print('Wrong learning input!')\n",
    "                sys.exit()    \n",
    "                \n",
    "            if n_state.end_state == 1:\n",
    "                break\n",
    "            if n_state.reward == REWARD:\n",
    "                temp_bounce+=1\n",
    "            cur_state = n_state\n",
    "        tot_bounce+=temp_bounce\n",
    "        if i%1000 == 0:\n",
    "            print('loop',i)\n",
    "            print('now average bounce in this 1000 round is', (tot_bounce-pre_tot)/1000)\n",
    "            print('bounce=',tot_bounce-pre_tot)\n",
    "            print()\n",
    "            graph.append(tot_bounce/i)\n",
    "            pre_tot = tot_bounce\n",
    "    return graph\n",
    "#================DEFINE TEST FUNCTION============\n",
    "def test(epoch_num,q_ag,mode = 'Part1.1'):\n",
    "    print('testing')\n",
    "    tot_bounce = 0\n",
    "    for i in range(epoch_num):\n",
    "        temp_bounce = 0\n",
    "        \n",
    "        if mode == 'Part1.1':\n",
    "            cur_state = state(0.5, 0.5, 0.03, 0.01, 0.5 - PADDLE_H / 2,0)\n",
    "        elif mode == 'Part1.2':\n",
    "            cur_state = state(0.5, 0.5, -0.03, 0.01, 0.5 - PADDLE_H / 2,0)\n",
    "            \n",
    "        while True:\n",
    "            action = q_ag.get_act(cur_state,i,mode='hei')\n",
    "            n_state = proceed_one_step(cur_state,ACTION_DIC[action],mode)\n",
    "            if n_state.end_state == 1:\n",
    "                break\n",
    "            if n_state.reward == REWARD:\n",
    "                temp_bounce+=1\n",
    "            cur_state = n_state\n",
    "        tot_bounce+=temp_bounce\n",
    "    \n",
    "    print('the avg bounce =',tot_bounce/epoch_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=========================VISUALIZATION VERSION========================\n",
    "WHITE = (255, 255, 255)\n",
    "BLACK = (0,0,0)\n",
    "BALL_COLOR = (255,186,186)\n",
    "PAD_COLOR = (182, 209, 204)\n",
    "BACKGROUND_COLOR = (255, 245, 222)\n",
    "SCORE_COLOR = (25, 118, 210)\n",
    "\n",
    "WIDTH = 600\n",
    "HEIGHT = 600\n",
    "\n",
    "BALL_RADIUS = 8\n",
    "PAD_WIDTH = 8\n",
    "PAD_HEIGHT = HEIGHT * 0.2\n",
    "HALF_PAD_WIDTH = PAD_WIDTH // 2\n",
    "HALF_PAD_HEIGHT = PAD_HEIGHT // 2\n",
    "GAME_FPS = 30\n",
    "GAME_END_FPS = 30\n",
    "\n",
    "def draw(canvas, ball_x, ball_y, paddle_y, mode = 'Part1.1', player_x = 0, player_y = 0, player_pad = 0):\n",
    "    canvas.fill(BACKGROUND_COLOR)\n",
    "#     pygame.draw.line(canvas, WHITE, [WIDTH // 2, 0], [WIDTH // 2, HEIGHT], 1)\n",
    "#     pygame.draw.line(canvas, WHITE, [PAD_WIDTH, 0], [PAD_WIDTH, HEIGHT], 1)\n",
    "#     pygame.draw.line(canvas, WHITE, [WIDTH - PAD_WIDTH, 0], [WIDTH - PAD_WIDTH, HEIGHT], 1)\n",
    "\n",
    "    if mode == 'Part1.1':\n",
    "        paddle1_pos = (WIDTH + 1 - HALF_PAD_WIDTH, int(paddle_y * HEIGHT + HALF_PAD_HEIGHT))\n",
    "        ball_pos = (int(ball_x * WIDTH) , int(ball_y * HEIGHT))\n",
    "\n",
    "        pygame.draw.circle(canvas, BALL_COLOR, ball_pos, BALL_RADIUS, 0)\n",
    "        pygame.draw.polygon(canvas, PAD_COLOR, [[paddle1_pos[0] - HALF_PAD_WIDTH, paddle1_pos[1] - HALF_PAD_HEIGHT],\n",
    "                                            [paddle1_pos[0] - HALF_PAD_WIDTH, paddle1_pos[1] + HALF_PAD_HEIGHT],\n",
    "                                            [paddle1_pos[0] + HALF_PAD_WIDTH, paddle1_pos[1] + HALF_PAD_HEIGHT],\n",
    "                                            [paddle1_pos[0] + HALF_PAD_WIDTH, paddle1_pos[1] - HALF_PAD_HEIGHT]], 0)\n",
    "\n",
    "    if mode == 'Part1.2':\n",
    "        paddle1_pos = (0 - 1 + HALF_PAD_WIDTH, int(paddle_y * HEIGHT + HALF_PAD_HEIGHT))\n",
    "        ball_pos = (int(ball_x * WIDTH) , int(ball_y * HEIGHT))\n",
    "\n",
    "        pygame.draw.circle(canvas, BALL_COLOR, ball_pos, BALL_RADIUS, 0)\n",
    "        pygame.draw.polygon(canvas, PAD_COLOR, [[paddle1_pos[0] - HALF_PAD_WIDTH, paddle1_pos[1] - HALF_PAD_HEIGHT],\n",
    "                                            [paddle1_pos[0] - HALF_PAD_WIDTH, paddle1_pos[1] + HALF_PAD_HEIGHT],\n",
    "                                            [paddle1_pos[0] + HALF_PAD_WIDTH, paddle1_pos[1] + HALF_PAD_HEIGHT],\n",
    "                                            [paddle1_pos[0] + HALF_PAD_WIDTH, paddle1_pos[1] - HALF_PAD_HEIGHT]], 0)\n",
    "\n",
    "\n",
    "def play(agent, epoches, mode = 'Part1.1'):\n",
    "    \n",
    "    pygame.init()\n",
    "    fps = pygame.time.Clock()\n",
    "\n",
    "    window = pygame.display.set_mode((WIDTH, HEIGHT))\n",
    "    pygame.display.set_caption('Pong')\n",
    "\n",
    "\n",
    "    \n",
    "    rscore = 0\n",
    "\n",
    "    for i in range(epoches):\n",
    "        bounce = 0\n",
    "        temp_bounce = 0\n",
    "        if mode == 'Part1.1':\n",
    "            cur_state = state(0.5, 0.5, 0.03, 0.01, 0.5 - PADDLE_H / 2,0)\n",
    "        elif mode == 'Part1.2':\n",
    "            cur_state = state(0.5, 0.5, -0.03, 0.01, 0.5 - PADDLE_H / 2,0)\n",
    "        while True: \n",
    "            \n",
    "            action = agent.get_act(cur_state,i,mode='hei')\n",
    "            for event in pygame.event.get():\n",
    "                if event.type == pygame.QUIT:\n",
    "                    pygame.quit()\n",
    "                    sys.exit()\n",
    "            \n",
    "            \n",
    "            n_state = proceed_one_step(cur_state,ACTION_DIC[action],mode)\n",
    "            \n",
    "            \n",
    "            if n_state.end_state == 1:\n",
    "                break\n",
    "            \n",
    "            draw(window, n_state.ball_x, n_state.ball_y, n_state.paddle_y,mode)\n",
    "            \n",
    "            pygame.display.update()\n",
    "            fps.tick(GAME_FPS)\n",
    "            cur_state = n_state\n",
    "            bounce+=n_state.reward\n",
    "        fps.tick(GAME_END_FPS)\n",
    "        print(bounce)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading past data...\n",
      "successfully load data\n",
      "loading past data...\n",
      "successfully load data\n"
     ]
    }
   ],
   "source": [
    "#======I'VE ALREAD TRAINED THE Q-AGENT SO JUST LOAD==========\n",
    "q_td = q_agent('load','Q')\n",
    "q_sa = q_agent('load','SARSA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully generate a new Q-Agent!\n",
      "loop 1000\n",
      "now average bounce in this 1000 round is 1.026\n",
      "bounce= 1026\n",
      "\n",
      "loop 2000\n",
      "now average bounce in this 1000 round is 1.418\n",
      "bounce= 1418\n",
      "\n",
      "loop 3000\n",
      "now average bounce in this 1000 round is 1.571\n",
      "bounce= 1571\n",
      "\n",
      "loop 4000\n",
      "now average bounce in this 1000 round is 1.786\n",
      "bounce= 1786\n",
      "\n",
      "loop 5000\n",
      "now average bounce in this 1000 round is 1.902\n",
      "bounce= 1902\n",
      "\n",
      "loop 6000\n",
      "now average bounce in this 1000 round is 2.154\n",
      "bounce= 2154\n",
      "\n",
      "loop 7000\n",
      "now average bounce in this 1000 round is 2.309\n",
      "bounce= 2309\n",
      "\n",
      "loop 8000\n",
      "now average bounce in this 1000 round is 2.359\n",
      "bounce= 2359\n",
      "\n",
      "loop 9000\n",
      "now average bounce in this 1000 round is 2.651\n",
      "bounce= 2651\n",
      "\n",
      "loop 10000\n",
      "now average bounce in this 1000 round is 2.851\n",
      "bounce= 2851\n",
      "\n",
      "loop 11000\n",
      "now average bounce in this 1000 round is 2.986\n",
      "bounce= 2986\n",
      "\n",
      "loop 12000\n",
      "now average bounce in this 1000 round is 3.184\n",
      "bounce= 3184\n",
      "\n",
      "loop 13000\n",
      "now average bounce in this 1000 round is 3.353\n",
      "bounce= 3353\n",
      "\n",
      "loop 14000\n",
      "now average bounce in this 1000 round is 3.748\n",
      "bounce= 3748\n",
      "\n",
      "loop 15000\n",
      "now average bounce in this 1000 round is 3.837\n",
      "bounce= 3837\n",
      "\n",
      "loop 16000\n",
      "now average bounce in this 1000 round is 3.786\n",
      "bounce= 3786\n",
      "\n",
      "loop 17000\n",
      "now average bounce in this 1000 round is 4.18\n",
      "bounce= 4180\n",
      "\n",
      "loop 18000\n",
      "now average bounce in this 1000 round is 4.616\n",
      "bounce= 4616\n",
      "\n",
      "loop 19000\n",
      "now average bounce in this 1000 round is 5.303\n",
      "bounce= 5303\n",
      "\n",
      "loop 20000\n",
      "now average bounce in this 1000 round is 5.457\n",
      "bounce= 5457\n",
      "\n",
      "loop 21000\n",
      "now average bounce in this 1000 round is 5.722\n",
      "bounce= 5722\n",
      "\n",
      "loop 22000\n",
      "now average bounce in this 1000 round is 5.867\n",
      "bounce= 5867\n",
      "\n",
      "loop 23000\n",
      "now average bounce in this 1000 round is 6.315\n",
      "bounce= 6315\n",
      "\n",
      "loop 24000\n",
      "now average bounce in this 1000 round is 6.252\n",
      "bounce= 6252\n",
      "\n",
      "loop 25000\n",
      "now average bounce in this 1000 round is 7.045\n",
      "bounce= 7045\n",
      "\n",
      "loop 26000\n",
      "now average bounce in this 1000 round is 7.03\n",
      "bounce= 7030\n",
      "\n",
      "loop 27000\n",
      "now average bounce in this 1000 round is 7.403\n",
      "bounce= 7403\n",
      "\n",
      "loop 28000\n",
      "now average bounce in this 1000 round is 7.663\n",
      "bounce= 7663\n",
      "\n",
      "loop 29000\n",
      "now average bounce in this 1000 round is 8.019\n",
      "bounce= 8019\n",
      "\n",
      "loop 30000\n",
      "now average bounce in this 1000 round is 8.035\n",
      "bounce= 8035\n",
      "\n",
      "loop 31000\n",
      "now average bounce in this 1000 round is 7.787\n",
      "bounce= 7787\n",
      "\n",
      "loop 32000\n",
      "now average bounce in this 1000 round is 7.759\n",
      "bounce= 7759\n",
      "\n",
      "loop 33000\n",
      "now average bounce in this 1000 round is 7.227\n",
      "bounce= 7227\n",
      "\n",
      "loop 34000\n",
      "now average bounce in this 1000 round is 7.815\n",
      "bounce= 7815\n",
      "\n",
      "loop 35000\n",
      "now average bounce in this 1000 round is 7.757\n",
      "bounce= 7757\n",
      "\n",
      "loop 36000\n",
      "now average bounce in this 1000 round is 7.91\n",
      "bounce= 7910\n",
      "\n",
      "loop 37000\n",
      "now average bounce in this 1000 round is 8.271\n",
      "bounce= 8271\n",
      "\n",
      "loop 38000\n",
      "now average bounce in this 1000 round is 8.161\n",
      "bounce= 8161\n",
      "\n",
      "loop 39000\n",
      "now average bounce in this 1000 round is 8.026\n",
      "bounce= 8026\n",
      "\n",
      "loop 40000\n",
      "now average bounce in this 1000 round is 8.406\n",
      "bounce= 8406\n",
      "\n",
      "loop 41000\n",
      "now average bounce in this 1000 round is 8.381\n",
      "bounce= 8381\n",
      "\n",
      "loop 42000\n",
      "now average bounce in this 1000 round is 8.337\n",
      "bounce= 8337\n",
      "\n",
      "loop 43000\n",
      "now average bounce in this 1000 round is 8.269\n",
      "bounce= 8269\n",
      "\n",
      "loop 44000\n",
      "now average bounce in this 1000 round is 8.532\n",
      "bounce= 8532\n",
      "\n",
      "loop 45000\n",
      "now average bounce in this 1000 round is 8.533\n",
      "bounce= 8533\n",
      "\n",
      "loop 46000\n",
      "now average bounce in this 1000 round is 8.236\n",
      "bounce= 8236\n",
      "\n",
      "loop 47000\n",
      "now average bounce in this 1000 round is 8.53\n",
      "bounce= 8530\n",
      "\n",
      "loop 48000\n",
      "now average bounce in this 1000 round is 8.287\n",
      "bounce= 8287\n",
      "\n",
      "loop 49000\n",
      "now average bounce in this 1000 round is 8.29\n",
      "bounce= 8290\n",
      "\n",
      "loop 50000\n",
      "now average bounce in this 1000 round is 8.227\n",
      "bounce= 8227\n",
      "\n",
      "loop 51000\n",
      "now average bounce in this 1000 round is 8.091\n",
      "bounce= 8091\n",
      "\n",
      "loop 52000\n",
      "now average bounce in this 1000 round is 8.268\n",
      "bounce= 8268\n",
      "\n",
      "loop 53000\n",
      "now average bounce in this 1000 round is 8.396\n",
      "bounce= 8396\n",
      "\n",
      "loop 54000\n",
      "now average bounce in this 1000 round is 8.543\n",
      "bounce= 8543\n",
      "\n",
      "loop 55000\n",
      "now average bounce in this 1000 round is 8.509\n",
      "bounce= 8509\n",
      "\n",
      "loop 56000\n",
      "now average bounce in this 1000 round is 8.205\n",
      "bounce= 8205\n",
      "\n",
      "loop 57000\n",
      "now average bounce in this 1000 round is 8.629\n",
      "bounce= 8629\n",
      "\n",
      "loop 58000\n",
      "now average bounce in this 1000 round is 8.705\n",
      "bounce= 8705\n",
      "\n",
      "loop 59000\n",
      "now average bounce in this 1000 round is 8.586\n",
      "bounce= 8586\n",
      "\n",
      "loop 60000\n",
      "now average bounce in this 1000 round is 8.077\n",
      "bounce= 8077\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#======ELSE WE CAN DO THIS TO TRAIN==========================\n",
    "q_td = q_agent()\n",
    "# tsa = train(100000,q_sa,'Part1.1','Q')\n",
    "# np.save('qtable_sa', q_sa.q_table)\n",
    "# np.save('tablevis_sa', q_sa.table_vis)\n",
    "\n",
    "# _1_2_sa = train(60000,q_sa,'Part1.2','SARSA')\n",
    "ppopo = train(60000,q_td,'Part1.1','Q')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.942"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "names = ['Ball-X','Ball-Y','Velocity-X','Velocity-Y','Paddle-Y','Action']\n",
    "expert = pd.read_csv('../part2/expert_policy.txt', sep=\" \", names=names)\n",
    "x = expert.iloc[:,0:5]\n",
    "y = expert.iloc[:,5:6]\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(256,256,256),max_iter=150,learning_rate_init=0.001,shuffle=True,batch_size=100,tol=-0.5,early_stopping=True)\n",
    "mlp.fit(x, y.values.ravel())\n",
    "mlp.score(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch_num,q_ag,mlp):\n",
    "    print('testing')\n",
    "    qag_win = 0\n",
    "    for i in range(epoch_num):\n",
    "        qag_bounce = 0\n",
    "        mlp_bounce = 0\n",
    "        cur_state = state(0.5, 0.5, 0.03, 0.01, 0.5 - PADDLE_H / 2,0)\n",
    "        while True:\n",
    "            action = q_ag.get_act(cur_state,i,mode='hei')\n",
    "            n_state = proceed_one_step(cur_state,ACTION_DIC[action],mode='Part1.1')\n",
    "            if n_state.end_state == 1:\n",
    "                break\n",
    "            if n_state.reward == REWARD:\n",
    "                qag_bounce+=1\n",
    "            cur_state = n_state\n",
    "            \n",
    "        cur_state = state(0.5, 0.5, 0.03, 0.01, 0.5 - PADDLE_H / 2,0)\n",
    "        while True:\n",
    "            action = mlp.predict([list(cur_state.state_tuple)])[0]\n",
    "            n_state = proceed_one_step(cur_state,ACTION_DIC[action])\n",
    "            if n_state.end_state == 1:\n",
    "                break\n",
    "            if n_state.reward == REWARD:\n",
    "                mlp_bounce+=1\n",
    "            cur_state = n_state\n",
    "        \n",
    "        qag_win = qag_win + 1*(qag_bounce>mlp_bounce) + 0.5*(qag_bounce==mlp_bounce)\n",
    "    \n",
    "    print('qag_win =',qag_win)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_state = state(0.5, 0.5, 0.03, 0.01, 0.5 - PADDLE_H / 2,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing\n",
      "qag_win = 605.0\n"
     ]
    }
   ],
   "source": [
    "test(1000,q_td,mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
